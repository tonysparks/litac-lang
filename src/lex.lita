import "std/string_view"
import "std/string_buffer"
import "std/libc"
import "std/mem"
import "std/string"
import "std/unicode/utf8"
import "std/assert"
//import "std/intrinsics"

import "types"

@asStr
public enum TokenType {
    // Start Keywords
    IMPORT,

    STRUCT,
    UNION,
    TRAIT,
    ENUM,
    FUNC,
    TYPEDEF,
    NOTE,
    VAR,
    CONST,

    NULL,
    VOID,
    TRUE,
    FALSE,
    BOOL,
    CHAR,
    I8,
    U8,
    I16,
    U16,
    I32,
    U32,
    I64,
    U64,
    F32,
    F64,
    USIZE,

    FOR,
    WHILE,
    DO,
    IF,
    ELSE,
    SWITCH,
    CASE,
    DEFAULT,
    DEFER,

    BREAK,
    CONTINUE,
    RETURN,
    GOTO,

    SIZEOF,
    TYPEOF,
    OFFSETOF,

    AS,
    PUBLIC,
    INTERNAL,
    USING,
    // End KeyWords

    // Symbols
    PLUS,
    MINUS,
    STAR,
    MOD,
    SLASH,
    BACK_SLASH,
    DOLLAR,
    HASH,
    DOT,
    VAR_ARGS,
    AT,
    QUESTION_MARK,
    COMMA,
    SEMICOLON,
    COLON,
    COLON_COLON,
    DOUBLE_QUOTE,

    LESS_THAN,
    LESS_EQUALS,
    GREATER_THAN,
    GREATER_EQUALS,
    EQUALS_EQUALS,
    EQUALS,
    NOT_EQUALS,
    PLUS_EQ,
    MINUS_EQ,
    DIV_EQ,
    MUL_EQ,
    MOD_EQ,
    LSHIFT_EQ,
    RSHIFT_EQ,
    BNOT_EQ,
    XOR_EQ,
    BAND_EQ,
    BOR_EQ,

    LSHIFT,
    RSHIFT,
    BNOT,
    XOR,
    BAND,
    BOR,

    LEFT_PAREN,
    RIGHT_PAREN,
    LEFT_BRACKET,
    RIGHT_BRACKET,
    LEFT_BRACE,
    RIGHT_BRACE,

    NOT,
    OR,
    AND,
    // Symbol End

    STRING,
    IDENTIFIER,
    INT_NUMBER,
    FLOAT_NUMBER,
    ERROR,
    END_OF_FILE,

    MAX_TOKEN_TYPES
}

public const tokenText = [TokenType.MAX_TOKEN_TYPES]*const char {
    [TokenType.IMPORT] = "import",

    [TokenType.STRUCT] = "struct",
    [TokenType.UNION] = "union",
    [TokenType.TRAIT] = "trait",
    [TokenType.ENUM] = "enum",
    [TokenType.FUNC] = "func",
    [TokenType.TYPEDEF] = "typedef",
    [TokenType.NOTE] = "@note",
    [TokenType.VAR] = "var",
    [TokenType.CONST] = "const",

    [TokenType.NULL] = "null",
    [TokenType.VOID] = "void",
    [TokenType.TRUE] = "true",
    [TokenType.FALSE] = "false",
    [TokenType.BOOL] = "bool",
    [TokenType.CHAR] = "char",
    [TokenType.I8] = "i8",
    [TokenType.U8] = "u8",
    [TokenType.I16] = "i16",
    [TokenType.U16] = "u16",
    [TokenType.I32] = "i32",
    [TokenType.U32] = "u32",
    [TokenType.I64] = "i64",
    [TokenType.U64] = "u64",
    [TokenType.F32] = "f32",
    [TokenType.F64] = "f64",
    [TokenType.USIZE] = "usize",

    [TokenType.FOR] = "for",
    [TokenType.WHILE] = "while",
    [TokenType.DO] = "do",
    [TokenType.IF] = "if",
    [TokenType.ELSE] = "else",
    [TokenType.SWITCH] = "switch",
    [TokenType.CASE] = "case",
    [TokenType.DEFAULT] = "default",
    [TokenType.DEFER] = "defer",

    [TokenType.BREAK] = "break",
    [TokenType.CONTINUE] = "continue",
    [TokenType.RETURN] = "return",
    [TokenType.GOTO] = "goto",

    [TokenType.SIZEOF] = "sizeof",
    [TokenType.TYPEOF] = "typeof",
    [TokenType.OFFSETOF] = "offsetof",

    [TokenType.AS] = "as",
    [TokenType.PUBLIC] = "public",
    [TokenType.INTERNAL] = "internal",
    [TokenType.USING] = "using",

    // End KeyWords

    // Symbols
    [TokenType.PLUS] = "+",
    [TokenType.MINUS] = "-",
    [TokenType.STAR] = "*",
    [TokenType.MOD] = "%",
    [TokenType.SLASH] = "/",
    [TokenType.BACK_SLASH] = "\\",
    [TokenType.DOLLAR] = "$",
    [TokenType.HASH] = "#",
    [TokenType.DOT] = ".",
    [TokenType.VAR_ARGS] = "...",
    [TokenType.AT] = "@",
    [TokenType.QUESTION_MARK] = "?",
    [TokenType.COMMA] = ",",
    [TokenType.SEMICOLON] = ";",
    [TokenType.COLON] = ":",
    [TokenType.COLON_COLON] = "::",
    [TokenType.DOUBLE_QUOTE] = "\"",

    [TokenType.LESS_THAN] = "<",
    [TokenType.LESS_EQUALS] = "<=",
    [TokenType.GREATER_THAN] = ">",
    [TokenType.GREATER_EQUALS] = ">=",
    [TokenType.EQUALS_EQUALS] = "==",
    [TokenType.EQUALS] = "=",
    [TokenType.NOT_EQUALS] = "!=",
    [TokenType.PLUS_EQ] = "+=",
    [TokenType.MINUS_EQ] = "-=",
    [TokenType.DIV_EQ] = "/=",
    [TokenType.MUL_EQ] = "*=",
    [TokenType.MOD_EQ] = "%=",
    [TokenType.LSHIFT_EQ] = "<<=",
    [TokenType.RSHIFT_EQ] = ">>=",
    [TokenType.BNOT_EQ] = "~=",
    [TokenType.XOR_EQ] = "^=",
    [TokenType.BAND_EQ] = "&=",
    [TokenType.BOR_EQ] = "|=",

    [TokenType.LSHIFT] = "<<",
    [TokenType.RSHIFT] = ">>",
    [TokenType.BNOT] = "~",
    [TokenType.XOR] = "^",
    [TokenType.BAND] = "&",
    [TokenType.BOR] = "|",

    [TokenType.LEFT_PAREN] = "(",
    [TokenType.RIGHT_PAREN] = ")",
    [TokenType.LEFT_BRACKET] = "[",
    [TokenType.RIGHT_BRACKET] = "]",
    [TokenType.LEFT_BRACE] = "{",
    [TokenType.RIGHT_BRACE] = "}",

    [TokenType.NOT] = "!",
    [TokenType.OR] = "||",
    [TokenType.AND] = "&&",

    [TokenType.STRING] = "STRING",
    [TokenType.IDENTIFIER] = "IDENTIFER",
    [TokenType.INT_NUMBER] = "INT_NUMBER",
    [TokenType.FLOAT_NUMBER] = "FLOAT_NUMBER",
    [TokenType.ERROR] = "ERROR",
    [TokenType.END_OF_FILE] = "EOF",
};

const charToDigit = [256]i32 {
    ['0'] = 0,
    ['1'] = 1,
    ['2'] = 2,
    ['3'] = 3,
    ['4'] = 4,
    ['5'] = 5,
    ['6'] = 6,
    ['7'] = 7,
    ['8'] = 8,
    ['9'] = 9,
    ['a'] = 10, ['A'] = 10,
    ['b'] = 11, ['B'] = 11,
    ['c'] = 12, ['C'] = 12,
    ['d'] = 13, ['D'] = 13,
    ['e'] = 14, ['E'] = 14,
    ['f'] = 15, ['F'] = 15,
};

const escapeToChar = [256]char {
    ['b'] = '\b',
    ['f'] = '\f',
    ['n'] = '\n',
    ['r'] = '\r',
    ['t'] = '\t',
    ['\\'] = '\\',
    ['\''] = '\'',
    ['"'] = '"',  // "
    ['0'] = '\0',

    ['/'] = '/',
    //['v'] = '\v',
  //  ['b'] = '\b',
  //  ['a'] = '\a',
};

const MAX_KEYWORD_CACHE = 9
const keywordCache = [MAX_KEYWORD_CACHE]**const char {
    [0] = []*const char {
        null
    },
    [1] = []*const char {
        null
    },
    [2] = []*const char {
        "i8",
        "u8",
        "do",
        "if",
        "as",
        null,
    },
    [3] = []*const char {
        "var",
        "i16",
        "u16",
        "i32",
        "u32",
        "i64",
        "u64",
        "f32",
        "f64",
        "for",
        null
    },
    [4] = []*const char {
        "enum",
        "func",
        "null",
        "void",
        "true",
        "bool",
        "char",
        "else",
        "case",
        "goto",
        null
    },
    [5] = []*const char {
        "trait",
        "union",
        "const",
        "false",
        "usize",
        "defer",
        "while",
        "break",
        "using",
        "@note",
        null
    },
    [6] = []*const char {
        "import",
        "struct",
        "switch",
        "return",
        "sizeof",
        "typeof",
        "public",
        null
    },
    [7] = []*const char {
        "typedef",
        "default",
        null
    },
    [8] = []*const char {
        "continue",
        "offsetof",
        "internal",
        null
    },
}

const keywordCacheIndex = [MAX_KEYWORD_CACHE]*TokenType {
    [2] = []TokenType {
        TokenType.I8,
        TokenType.U8,
        TokenType.DO,
        TokenType.IF,
        TokenType.AS,
    },
    [3] = []TokenType {
        TokenType.VAR,
        TokenType.I16,
        TokenType.U16,
        TokenType.I32,
        TokenType.U32,
        TokenType.I64,
        TokenType.U64,
        TokenType.F32,
        TokenType.F64,
        TokenType.FOR,
    },
    [4] = []TokenType {
        TokenType.ENUM,
        TokenType.FUNC,
        TokenType.NULL,
        TokenType.VOID,
        TokenType.TRUE,
        TokenType.BOOL,
        TokenType.CHAR,
        TokenType.ELSE,
        TokenType.CASE,
        TokenType.GOTO,
    },
    [5] = []TokenType {
        TokenType.TRAIT,
        TokenType.UNION,
        TokenType.CONST,
        TokenType.FALSE,
        TokenType.USIZE,
        TokenType.DEFER,
        TokenType.WHILE,
        TokenType.BREAK,
        TokenType.USING,
        TokenType.NOTE,
    },
    [6] = []TokenType {
        TokenType.IMPORT,
        TokenType.STRUCT,
        TokenType.SWITCH,
        TokenType.RETURN,
        TokenType.SIZEOF,
        TokenType.TYPEOF,
        TokenType.PUBLIC,
    },
    [7] = []TokenType {
        TokenType.TYPEDEF,
        TokenType.DEFAULT,
    },
    [8] = []TokenType {
        TokenType.CONTINUE,
        TokenType.OFFSETOF,
        TokenType.INTERNAL,
    }
}

public struct SrcPos {
    filename: *const char
    lineStart: *const char

    start: *const char
    end: *const char
    lineNumber: i32
    position: i32
}

public union Value {
    floatValue: f64
    intValue: i64
    uintValue: u64
    str: StringView
}

public enum Mod {
    NONE = 0,
    MULTISTR,
}

public struct Token {
    type: TokenType
    mod: Mod
    typeInfo: *TypeInfo
    pos: SrcPos
    value: using Value
}

public func (token: *Token) nameEquals(str: *const char) : bool {
    if(token.type != TokenType.IDENTIFIER) {
        return false
    }

    return token.str.equals(str)
}

public func (p: *SrcPos) getLineLength() : i32 {
    if(!p.lineStart) return -1

    var len = 0
    while(p.lineStart[len] != '\0') {
        if(p.lineStart[len] == '\n') {
            break
        }
        len += 1
    }

    return len
}

@doc("""
There be dragons -- Uses a static buffer internally; do
not free this memory and do not rely on the memory being
correct for very long
""")
public func (t: *Token) asString() : *const char {
    @static var buffer: [260]char;
    if(t.type == TokenType.IDENTIFIER || t.type == TokenType.STRING) {
        var str = StringInit(buffer, 260, 0)
        str.format("%.*s", t.str.length, t.str.buffer)
        return str.cStr()
    }
    return tokenText[t.type]
}

public func (token: *Token) print() {
    printf("%s: '%s' '%.*s' ", TokenTypeAsStr(token.type), token.asString(), (token.pos.end - token.pos.start) as (i32), token.pos.start)
    if(token.type == TokenType.INT_NUMBER) {
        printf("value: '%d'", token.value.intValue as (i32))
        printf(" typeInfo: %s", TypeKindAsStr(token.typeInfo.kind))
    }
    else if(token.type == TokenType.FLOAT_NUMBER) {
        printf("value: '%f'", token.value.floatValue)
        printf(" typeInfo: %s", TypeKindAsStr(token.typeInfo.kind))
    }
    else if(token.type == TokenType.STRING) {
        printf("value: '%.*s'", token.value.str.length, token.value.str.buffer)
    }
    else if(token.type == TokenType.ERROR) {
        printf("error: '%s'", "X")
    }
    printf("\n")
}


public struct Lexer {
    allocator: *const Allocator
    filename: *const char
    token: Token
    stream: *const char
    length: i64

    lineStart: *const char
    lineNumber: i32
    position: i32

    errorMsg: *const char
}

public func LexerInit(filename: *const char,
                      text: *const char,
                      length: i64,
                      allocator: *const Allocator) : Lexer {
    return Lexer {
        .allocator = allocator,
        .token = Token {
            .type = TokenType.END_OF_FILE,
            .typeInfo = null,
            .pos = SrcPos {
                .filename = filename,
                .start = text,
                .end = null,
            }
        },
        .stream = text,
        .length = length,
        .lineStart = text,
        .lineNumber = 1,
        .position = 1,
        .errorMsg = null,
    }
}

public func (l: *Lexer) hasError() : bool {
    return l.errorMsg != null
}

func (l: *Lexer) error(format: *const char, ...) {
    var sb = StringBufferInit(256, l.allocator)

    var args: va_list;
    va_start(args, format);
    sb.appendArgs(format, args)
    va_end(args)

    l.errorMsg = sb.cStr()
    l.errorToken()
}

func (l: *Lexer) nextChar() : rune {
    var c = (*l.stream) as (u8)

    // check for non-ascii values
    if(c >= 0x80) {
        var result: rune = 0
        var len = Utf8Decode(l.stream as (*const u8), -1, &result)
        if(len < 0) {
            l.error("Invalid codepoint");
            return INVALID_RUNE
        }

        var width = Utf8CharWidth(result)

        l.stream += len
        l.position += width
        return result
    }

    // normal ascii
    if(c == '\n') {
        l.lineStart = l.stream + 1;
        l.lineNumber += 1;
        l.position = 0;
    }

    l.stream += 1
    l.position += 1
    return (*l.stream) as (rune)

}

public func (l: *Lexer) eofToken() : Token {
    l.token.type = TokenType.END_OF_FILE
    l.token.pos.lineStart = l.lineStart
    l.token.pos.lineNumber = l.lineNumber
    l.token.pos.position = l.position
    return l.token
}

func (l: *Lexer) errorToken() : Token {
    l.token.type = TokenType.ERROR
    l.token.pos.lineStart = l.lineStart
    l.token.pos.lineNumber = l.lineNumber
    l.token.pos.position = l.position
    return l.token
}

func (l: *Lexer) skipWhitespace() {
    while (isspace(*l.stream)) {
        l.nextChar()
    }
}

//func batchRead(str: *const char)
const commentEnd = "*/1234567890123456"

func (l: *Lexer) skipComments() {
    if(*l.stream == '/') {
        if(l.stream[1] == '/') {
            l.nextChar() // eat /
            do {
                l.nextChar()
                if(*l.stream == '\n') {
                    break;
                }
            }
            while(!l.eof())
        }
        else if(l.stream[1] == '*') {
/* TODO: Use intrinsics for faster lexing...
            const match = _mm_loadu_si128(commentEnd as (*__m128i))
            const carriage = _mm_set1_epi8('\n');

            l.nextChar() // eat /
            l.nextChar() // eat *

            var end   = l.length - 16
            var count = (l.stream + l.length) - (l.stream)

            while(count < end) {
                var batch = _mm_loadu_si128(l.stream as (*__m128i))

                var carriageRet = _mm_cmpeq_epi8(batch, carriage)

                // check for ending comment marker
                var result = _mm_cmpestri(match, 2, batch, 16, _SIDD_UBYTE_OPS|_SIDD_CMP_EQUAL_ORDERED|_SIDD_LEAST_SIGNIFICANT|_SIDD_BIT_MASK)
                if(result < 16) {
                    l.stream = l.stream + result + 2
                    goto found;
                }

                count     += 16
                l.stream  += 16
            }

            for(; count < l.length; count +=1) {
                var c = l.stream[count]
                if(c == '*' && l.stream[count + 1] == '/') {
                    l.stream = l.stream + count + 2
                    goto found;
                }
            }

            // end of the stream, with no closing comments...
            {
                return;
            }

            found:
            // TODO: need to calculate lineNumber and position...

*/
            l.nextChar() // eat /
            do {
                l.nextChar()
                if((l.stream[0] == '*' && l.stream[1] == '/')) {
                    l.nextChar()
                    l.nextChar()
                    break;
                }
            }
            while(!l.eof())
        }
    }
}

func (l: *Lexer) isValidIdentifierStart(c: char) : bool {
    return ((c == '_') ||
            (c >= 'A' && c <= 'Z') ||
            (c >= 'a' && c <= 'z'))
}

func (l: *Lexer) isValidIdentifierChar(c: char) : bool {
    return ((c == '_') ||
            (isdigit(c)) ||
            (isalpha(c)))
}

func (l: *Lexer) isSymbolStart(c: char) : bool {
    return((c > ' ' && c < '0') ||
           (c > '9' && c < 'A') ||
           (c > 'Z' && c < '_') ||
           (c > 'z' && c < 127));
}

func (l: *Lexer) checkKeyword() : bool {
    var len = l.token.str.length
    if(len < MAX_KEYWORD_CACHE) {
        var keywords = keywordCache[len]
        for(var i = 0;; i+=1) {
            var keyword = keywords[i]
            if(!keyword) break;

            if(strncmp(l.token.str.buffer, keyword, len) == 0) {
                l.token.type = keywordCacheIndex[len][i]
                return true
            }
        }
    }

    return false
}


func (l: *Lexer) scanWord() : Token {
    var length = 0
    while(l.isValidIdentifierChar(*l.stream)) {
        l.stream += 1
        length += 1
    }

    l.position += length
    l.token.pos.end = l.stream
    //l.token.pos.lineNumber = l.lineNumber
    l.token.type = TokenType.IDENTIFIER
    l.token.str = StringViewInit(l.token.pos.start, length)

    l.checkKeyword()

    return l.token
}

func (l: *Lexer) scanInt(stream: *char) {
    var base = 10;
    var start_digits = stream;

    if (*stream == '0') {
        stream += 1;

        if (tolower(*stream) == 'x') {
            stream += 1;
            base = 16;
            start_digits = stream;
        } else if (tolower(*stream) == 'b') {
            stream += 1;
            base = 2;
            start_digits = stream;
        } else if (isdigit(*stream)) {
            base = 8;
            start_digits = stream;
        }
    }
    var val: i64 = 0;
    for (;;) {
        var digit = charToDigit[(*stream) as (i32)];
        if (digit == 0 && *stream != '0') {
            break;
        }
        if (digit >= base) {
            l.error("Digit '%c' out of range for base %d", *stream, base);
            digit = 0;
        }
        if (val > (ULLONG_MAX - digit)/base) {
            l.error("Integer literal overflow");
            while (isdigit(*stream)) {
                stream += 1;
            }
            val = 0;
            break;
        }
        val = val*base + digit;
        stream += 1;
    }
    if (stream == start_digits) {
        l.error("Expected base %d digit, got '%c'", base, *stream);
    }

    if(l.hasError()) {
        return;
    }

    l.token.type = TokenType.INT_NUMBER;
    l.token.value.intValue = val
}

func (l: *Lexer) scanFloat(stream: *char) {
    var start = stream;

    while (isdigit(*stream)) {
        stream+=1;
    }
    if (*stream == '.') {
        stream+=1;
    }
    while (isdigit(*stream)) {
        stream+=1;
    }
    if (tolower(*stream) == 'e') {
        stream+=1;
        if (*stream == '+' || *stream == '-') {
            stream+=1;
        }
        if (!isdigit(*stream)) {
            l.error("Expected digit after float literal exponent, found '%c'.", *stream);
        }
        while (isdigit(*stream)) {
            stream+=1;
        }
    }
    var val = strtod(start, null);
    if (val == HUGE_VAL) {
        l.error("Float literal overflow");
    }

    if(l.hasError()) {
        return;
    }

    l.token.type = TokenType.FLOAT_NUMBER
    l.token.value.floatValue = val;
}

func (l: *Lexer) scanTypeInfo() {
    var c = *l.stream
    if(c == 'u' || c == 'i') {
        if(l.token.typeInfo == &F32_TYPE || l.token.typeInfo == &F64_TYPE) {
            l.error("Integer type designation on floating point number not allowed");
            return;
        }

        var start = l.stream
        var len = 0
        do {
            len += 1
            l.nextChar()

            if(!isdigit(*l.stream)) {
                break;
            }
        } while(!l.eof())

        var kind = TypeKindFromString(start, len)
        switch(kind) {
            case TypeKind.I8: {
                l.token.typeInfo = &I8_TYPE
                break;
            }
            case TypeKind.U8: {
                l.token.typeInfo = &U8_TYPE
                break;
            }
            case TypeKind.I16: {
                l.token.typeInfo = &I16_TYPE
                break;
            }
            case TypeKind.U16: {
                l.token.typeInfo = &U16_TYPE
                break;
            }
            case TypeKind.I32: {
                l.token.typeInfo = &I32_TYPE
                break;
            }
            case TypeKind.U32: {
                l.token.typeInfo = &U32_TYPE
                break;
            }
            case TypeKind.I64: {
                l.token.typeInfo = &I64_TYPE
                break;
            }
            case TypeKind.U64: {
                l.token.typeInfo = &U64_TYPE
                break;
            }
            default: {
                l.error("Invalid number type designator");
            }
        }

    }
    else if(tolower(c) == 'f' || tolower(c) == 'd' ) {
        var start = l.stream
        var len = 0
        do {
            len += 1
            l.nextChar()

            if(!isdigit(*l.stream)) {
                break;
            }
        } while(!l.eof())

        if(len == 1) {
            if(tolower(c) == 'f') {
                l.token.typeInfo = &F32_TYPE
            }
            else {
                l.token.typeInfo = &F64_TYPE
            }
        }
        else {
            var kind = TypeKindFromString(start, len)
            switch(kind) {
                case TypeKind.F32: {
                    l.token.typeInfo = &F32_TYPE
                    break;
                }
                case TypeKind.F64: {
                    l.token.typeInfo = &F64_TYPE
                    break;
                }
                default: {
                    l.error("Invalid number type designator");
                }
            }
        }
    }
}

func IsHex(c: rune) : bool {
    return isdigit(c) || IsHexChar(c)
}

func IsHexChar(c: char) : bool {
    c = tolower(c)
    return c == 'a' ||
           c == 'b' ||
           c == 'c' ||
           c == 'd' ||
           c == 'e' ||
           c == 'f'
}

func (l: *Lexer) scanNumber() : Token {
    var numBuf: [256]char;
    var numIndex = 0

    var hasDecimal = false
    var hasExpo = false
    var isHex = false
    while(!l.eof()) {
        var c = *l.stream
        if(c == '.') {
            if(hasDecimal) {
                break;
            }
            hasDecimal = true
        }
        else if(tolower(c) == 'e' && !isHex) {
            if(hasExpo) {
                break;
            }
            hasExpo = true
        }
        else if(!isdigit(c) && c != '_') {
            if(c == 'x' || c == 'X') {
                isHex = true
            }
            else if(isHex) {
                if(!IsHexChar(c)) {
                    break;
                }
            }
            else {
                break
            }
        }

        if(c != '_') {
            numBuf[numIndex] = c
            numIndex += 1
        }

        l.stream+=1
    }

    numBuf[numIndex] = '\0'
    if (hasDecimal || hasExpo) {
        l.scanFloat(numBuf);
        l.token.typeInfo = &F64_TYPE
    } else {
        l.scanInt(numBuf);

        l.token.typeInfo = &I32_TYPE
        if(l.token.value.intValue > INT_MAX) {
            if(l.token.value.intValue > UINT_MAX) {
                l.token.typeInfo = &I64_TYPE
            }
            else {
                l.token.typeInfo = &U32_TYPE
            }
        }
    }

    if(l.hasError()) {
        return l.errorToken()
    }

    l.scanTypeInfo()

    l.token.pos.end = l.stream
    //l.token.pos.position += (l.stream - start) as (i32)
    //l.token.pos.lineNumber = l.lineNumber
    return l.token
}

func (l: *Lexer) scanChar() : Token {
    var c: rune = l.nextChar() // eat the '
    var value: rune = '\0';
    var isValid = true

    if(c == '\\') {
        c = l.nextChar() // eat the \

        if(c == 'u' || c == 'U') {
            var count = 0
            var reqCount = c == 'u' ? 4 : 8
            var pos = l.stream

            for(;;) {
                c = l.nextChar()
                if(c == '\n' || c < 0) {
                    l.error("char literal not terminated")
                    return l.errorToken()
                }
                if(c == '\'') {
                    break
                }

                if(!IsHex(c)) {
                    l.error("invalid unicode codepoint hex component: '%c'", c)
                    isValid = false
                }

                count += 1
            }

            if(count != reqCount) {
                l.error("invalid unicode codepoint literal: '%.*s', must be %d hex digits in length", count + 1, pos, reqCount)
                isValid = false
            }

            if(isValid) {
                value = strtol(pos + 1, null, 16) as (rune)
            }

            if(isValid && !l.validateCodepoint(pos, count)) {
                isValid = false
            }
        }
        else if(c == 'x') {
            assert(false) // not done yet
        }
        else {
            if(c >= 256) {
                l.error("Illegal escaped character, character out of byte range (hex value): '%x'", c)
                return l.errorToken()
            }

            if(escapeToChar[c] == 0 && c != '0') {
                isValid = false
            }

            l.nextChar() // eat the character
            value = escapeToChar[c]
        }
    }
    else {
        value = c
        l.nextChar() // eat the character
    }

    if(value >= 256) {
        l.error("Illegal character literal, character out of byte range (hex value): '%x'", value)
        return l.errorToken()
    }

    if(*l.stream != '\'') {
        return l.errorToken()
    }

    l.nextChar() // eat the closing '

    if(!isValid) {
        return l.errorToken()
    }

    l.token.type = TokenType.CHAR
    l.token.pos.end = l.stream
    l.token.intValue = value
    return l.token
}

func (l: *Lexer) validateCodepoint(str: *const char, len: i32) : bool {
    if(len != 4 && len != 8) {
        l.error("invalid unicode codepoint literal: '%.*s'", len + 1, str)
        return false
    }

    var codepoint: rune = Utf8HexDecode(str + 1, len)
    if(!Utf8CodepointValid(codepoint)) {
        l.error("invalid unicode codepoint literal: '%.*s'", len + 1, str)
        return false
    }

    if(codepoint >= 0 /*0x0000*/ && codepoint <= 159 /*0x009f*/) {
        if(codepoint == 36 /*0x0024*/ || codepoint == 64 /*0x0040*/ || codepoint == 96 /*0x0060*/) {
            // exceptions
        }
        else {
            l.error("universal character name: '%.*s' refers to a control character.  A universal character name may not represent a character in the range 0000-009F, inclusive, with the exceptions of 0024 ('$'), 0040 ('@') and 0060 ('`')", len + 1, str)
            return false
        }
    }

    return true
}

func (l: *Lexer) scanString() : Token {
    var isVerbatim = false
    var isValid = true
    var startPos: *const char = null

    assert(l.stream[0] == '"')

    if(l.stream[1] == '"' && l.stream[2] == '"') {
        isVerbatim = true
        l.nextChar()
        l.nextChar()
    }

    l.nextChar()

    l.token.value.str.buffer = l.stream
    startPos = l.stream

    for(;;) {
        if(l.stream[0] == '\0') {
            l.error("string literal not terminated")
            isValid = false
            break
        }

        if(l.stream[0] == '\\') {
            var c = l.nextChar()

            // unicode codepoint
            if(c == 'u' || c == 'U') {
                var count = 0
                var reqCount = c == 'u' ? 4 : 8
                var pos = l.stream

                for(;;) {
                    c = l.nextChar()
                    if(c < 0) {
                        l.error("string literal not terminated")
                        isValid = false
                        break
                    }

                    if(count >= reqCount || c == ' ' || c == '\n' || c == '"') { // "
                        break
                    }

                    if(!IsHex(c)) {
                        l.error("invalid unicode codepoint hex component: '%c'", c)
                        isValid = false
                    }

                    count += 1
                }

                if(count != reqCount && isValid) {
                    l.error("invalid unicode codepoint literal: '%.*s', must be %d hex digits in length", count + 1, pos, reqCount)
                    isValid = false
                }

                if(isValid && !l.validateCodepoint(pos, count)) {
                    isValid = false
                }

                continue
            }
            else if(c == 'x') {
                assert(false) // not done yet
            }
            else {
                if(c >= 256) {
                    l.error("Illegal escaped character, character out of byte range (hex value): '%x'", c)
                    isValid = false
                    continue
                }

                if(escapeToChar[c] == 0 && c != '0') {
                    l.error("Illegal escaped character: '%c'", c)
                    isValid = false
                    continue
                }
            }
        }
        else if(l.stream[0] == '"') {
            if(!isVerbatim) {
                l.nextChar()
                break;
            }
            else if(l.stream[1] == '"' && l.stream[2] == '"') {
                l.nextChar()
                l.nextChar()
                l.nextChar()
                break;
            }
        }

        l.nextChar()
    }

    isValid = isValid && !l.hasError()

    l.token.type = TokenType.STRING
    l.token.pos.end = l.stream
    if(isVerbatim) {
        l.token.value.str.length = ((l.stream - startPos) - 3) as (i32)
        l.token.mod = Mod.MULTISTR
    }
    else {
        l.token.value.str.length = ((l.stream - startPos) - 1) as (i32)
        l.token.mod = Mod.NONE
    }

    return isValid ? l.token : l.errorToken()
}

func (l: *Lexer) scanSymbol() : Token {
    var c = *l.stream
    l.nextChar()
    switch(c) {
        case '+': {
            l.token.type = TokenType.PLUS
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.PLUS_EQ
            }
            break;
        }
        case '-': {
            l.token.type = TokenType.MINUS
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.MINUS_EQ
            }
            break;
        }
        case '*': {
            l.token.type = TokenType.STAR
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.MUL_EQ
            }
            break;
        }
        case '%': {
            l.token.type = TokenType.MOD
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.MOD_EQ
            }
            break;
        }
        case '/': {
            l.token.type = TokenType.SLASH
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.DIV_EQ
            }
            break;
        }
        case '$': {
            l.token.type = TokenType.DOLLAR
            break;
        }
        case '#': {
            l.token.type = TokenType.HASH
            break;
        }
        case '.': {
            l.token.type = TokenType.DOT
            if(l.stream[0] == '.') {
                if( l.stream[1] == '.') {
                    l.nextChar()
                    l.nextChar()
                    l.token.type = TokenType.VAR_ARGS
                }
            }
            break;
        }
        case '@': {
            l.token.type = TokenType.AT
            if(strncmp(l.stream, "note", 4) == 0) {
                l.token.type = TokenType.NOTE
                l.stream   += 4
                l.position += 4
            }
            break;
        }
        case '?': {
            l.token.type = TokenType.QUESTION_MARK
            break;
        }
        case ',': {
            l.token.type = TokenType.COMMA
            break;
        }
        case ';': {
            l.token.type = TokenType.SEMICOLON
            break;
        }
        case ':': {
            l.token.type = TokenType.COLON
            if(l.stream[0] == ':') {
                l.nextChar()
                l.token.type = TokenType.COLON_COLON
            }
            break;
        }
        case '"': { //"
            l.token.type = TokenType.DOUBLE_QUOTE
            break;
        }
        case '<': {
            l.token.type = TokenType.LESS_THAN
            if(l.stream[0]== '=') {
                l.nextChar()
                l.token.type = TokenType.LESS_EQUALS
            }
            else if(l.stream[0] == '<') {
                l.nextChar()
                l.token.type = TokenType.LSHIFT
                if( l.stream[0] == '=') {
                    l.nextChar()
                    l.token.type = TokenType.LSHIFT_EQ
                }
            }
            break;
        }
        // Special consideration for >> because this may be end of a generics
        // definition
        case '>': {
            l.token.type = TokenType.GREATER_THAN
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.GREATER_EQUALS
            }
            else if(l.stream[0] == '>' && l.stream[1] == '=') {
                l.nextChar()
                l.nextChar()
                l.token.type = TokenType.RSHIFT_EQ
            }
            break;
        }
        case '=': {
            l.token.type = TokenType.EQUALS
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.EQUALS_EQUALS
            }
            break;
        }
        case '!': {
            l.token.type = TokenType.NOT
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.NOT_EQUALS
            }
            break;
        }
        case '~': {
            l.token.type = TokenType.BNOT
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.BNOT_EQ
            }
            break;
        }
        case '^': {
            l.token.type = TokenType.XOR
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.XOR_EQ
            }
            break;
        }
        case '&': {
            l.token.type = TokenType.BAND
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.BAND_EQ
            }
            else if(l.stream[0] == '&') {
                l.nextChar()
                l.token.type = TokenType.AND
            }
            break;
        }
        case '|': {
            l.token.type = TokenType.BOR
            if(l.stream[0] == '=') {
                l.nextChar()
                l.token.type = TokenType.BOR_EQ
            }
            else if(l.stream[0] == '|') {
                l.nextChar()
                l.token.type = TokenType.OR
            }
            break;
        }
        case '(': {
            l.token.type = TokenType.LEFT_PAREN
            break;
        }
        case ')': {
            l.token.type = TokenType.RIGHT_PAREN
            break;
        }
        case '[': {
            l.token.type = TokenType.LEFT_BRACKET
            break;
        }
        case ']': {
            l.token.type = TokenType.RIGHT_BRACKET
            break;
        }
        case '{': {
            l.token.type = TokenType.LEFT_BRACE
            break;
        }
        case '}': {
            l.token.type = TokenType.RIGHT_BRACE
            break;
        }
        case '\\': {
            l.token.type = TokenType.BACK_SLASH
            break;
        }
        default: {
            return l.errorToken();
        }
    }

    l.token.pos.end = l.stream
    //l.token.pos.lineNumber = l.lineNumber
    return l.token
}

public func (l: *Lexer) eof() : bool {
    return *l.stream == '\0'
}


public func (l: *Lexer) nextToken() : Token {

repeat:
    if(l.eof()) {
        return l.eofToken()
    }
    l.skipComments()

    l.errorMsg = null // clear out errors

    l.token.pos.lineNumber = l.lineNumber
    l.token.pos.lineStart = l.lineStart
    l.token.pos.start = l.stream
    l.token.pos.position = l.position
    l.token.typeInfo = null

    var c = *l.stream
    switch(c) {
        case '\0': {
            return l.eofToken()
        }
        case ' ':
        case '\n':
        case '\r':
        case '\t': {
        //case '\v':
            l.skipWhitespace()
            goto repeat;
        }
        case '"': { // "
            return l.scanString()
        }
        case '\'': {
            return l.scanChar()
        }
        default: {
            if(l.isValidIdentifierStart(c)) {
                return l.scanWord()
            }

            if(isdigit(c)) {
                return l.scanNumber()
            }

            if(l.isSymbolStart(c)) {
                return l.scanSymbol()
            }


            var n = l.nextChar()
            var invalidChar: [4]u8;
            var len = Utf8Encode(n, invalidChar)

            l.error("unexpected character: '%.*s'", len, invalidChar)
            return l.errorToken()
        }
    }

    return l.eofToken()
}